## Bounded Buffer

BB是对通信的虚拟化，可以认为是对网线的虚拟化，所以叫virtua link。

在介绍完虚拟内存后，我们知道两个地址空间是可以完全独立的，彼此不能访问。如果让每个模块都独有一个地址空间，虽然有很好的隔离性，但这也会妨碍模块与模块之间的交互，无法实现C/S架构。

总的来说，在一台主机上的两个模块之间进行通信，主要有两种方法：共享一部分内存，或让第三方在中间传递message。对第二种情况，我们提出bounded buffer模型。

BB是在内核中的一段内存，用户态不能直接通过load和store访问（因为页表U/S位的保护），而必须通过内核提供的SEND/RECEIVE接口来访问，这两个接口通过system call实现。这有点像在面向对象编程中，一个对象的私有字段必须通过方法来访问。其目的是为了让内核能够完全控制这段buffer以及对这段buffer的访问。

有了这个架构后，接下来就面临着“生产者和消费者问题”，即：发送方在BB满时，接收方在BB空时，必须等待；换句话说，生产者和消费者需要进行顺序协调（sequence coordination）。

**单个sender和单个receiver**

我们来看send(bb, m)的代码实现。首先要注意的是if语句，判断是否满，如果满则通过while不断spin等待；如果不满则把message放到buffer中。buf是一个数组，通过mod操作作为一个ring，到底了就绕到前面。in是不断增加的，这里有整数溢出的问题（暂不考虑）。注意4和5不能换，因为要考虑并发情况，即有一个receiver同时在运行，如果先执行5，那么receiver看到in已经增加就会去读，但4还没执行所以receiver读到的是垃圾数据（或旧数据）。

再来看receive(bb, m)的代码实现，非常类似，但操作的是out变量，if判断的条件也变成了是否为空；4和5也不能交换顺序。

这两个函数的实现非常简洁，而且能够并发运行在两个CPU上，这并不寻常——因为实现并没有用到锁。CSE的一个思维是，一旦程序同时运行在多核上，总可能出些错。

**多个sender或多个receiver**

错误马上来了。如果存在多个sender，那么它们就可能同时访问in变量，导致竞争条件（race condition）；即程序的运行结果与指令调度（schedule）相关。由于指令的调度本身是不可控制的（这是一个前提），所以导致运行结果不可控制。

这里需要讨论几点。首先，Race是说结果与schedule相关，并不是说一定错，比如一套代码，两次运行结果不同（因为schedule不同），但这两次的结果可能都是对的。比如A->B转账100元和银行算利息10%这两个操作并发运行（假设利息就是固定天发放，不考虑钱存多久），有两种结果：100元的利息算给了A，B只拿到100元；A先给B转100元，这100的利息算给了B。这两种结果都是对的。

其次，调度不可控是一个前提假设。有人可能会问，难道执行本身不是确定性的么？并不是。在多核上运行代码，导致执行序列变化的原因还是在于复杂性——在指令这个极细的粒度去考虑schedule，影响因素是很多的，比如cache。我们对OS在thread级的调度其实已经不可控了，所以我们这里假设指令调度不可控。为了解决这个问题，学术上有DMT和RR等方法，希望去掉指令调度的非确定性，这点我们以后再说。

为了解决Race的问题，我们引入了锁（lock）的抽象。锁是一种广泛使用的抽象，例如数据库、OS、体系结构等，通常用来保证某一组操作的原子性。锁对程序员的要求是很高的，程序员需要首先分析出所有可能出现race的地方，然后用锁把这段代码保护起来。

具体使用方面，总的来说非常简单：首先要acquire一把锁，然后执行关键的代码，然后release这把锁。在acquire()时，若锁在别的thread手里，那么当前thread就会block，不往下执行；可以是spin在某一条指令上不断循环（spinlock，不让出CPU），或者暂时让出CPU（condition variable）。这里要求所有代码都遵循相同的规则，例如访问某个变量之前先要acquire对应的锁，访问完后release这把锁。但要注意，并没有任何强制性的措施保证这一点，即如果有一行代码写错了，在没有拿到锁就访问某个变量，那么编译器是不会报错的，这属于程序员的逻辑错误。常见的错误就是忘了acquire()，或者acquire()两次，或者忘了release()。锁也可能对性能产生影响，某个thread拿了锁然后运行很长时间，导致其他thread不得不等着。另外，还可能遇到deadlock和livelock的问题。这些我们后面都会介绍。

接下来看如何用lock改造我们的send()和receive()，使之能够支持多个sender或多个receiver。先看一个版本，当buffer为FULL时不断等待，一旦NOT-FULL则拿锁后运行关键代码，保证只有一个thread能够修改buffer数组和in变量。这个版本有一个问题，即在not-full这一条件成立后，在拿锁之前，有可能有2个sender同时执行在这里，这两个sender都以为条件已经成立，于是第二个sender会导致数据覆盖。这里的问题在于，锁只保护了in和buffer，却没有保护NOT-FULL这个条件，而这一层完全属于程序的语义，必须靠程序员想清楚。思考的方式在于：在脑子里遍历各种可能的情况，并判断这些情况是否正确。对于这个例子，我们看到if语句中有对in的读操作，并不在锁的保护范围之内，这是一个很可能出错的现象，即对于某一个变量没有保护完全，所以我们有了一个改进的版本，将读操作也放到锁保护的范围，就可以解决这个问题。

要注意的是，新版本有一个特点：拿着锁运行循环。有人可能会想，拿锁时间应当尽量少，怎么能运行循环呢？对性能是不是有较大的影响？确实是这样，但我们今天的假设是每个模块（thread）独占一个CPU，所以先不考虑CPU浪费的事情，在这边就用spin的方式将当前运行block住。如果用yield CPU的方式而不是spin，那么这段代码又要有更新。

为了避免race，需要引入before-or-after的特性，即两个操作（更准确的说是两组指令），从结果来看，或者A在B前面，或者相反。这里的重点在于**从结果来定义正确性**，然后再反过来推导该如何去设计。

